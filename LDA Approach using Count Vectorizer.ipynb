{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA OR Latent Dirchlet Allocation\n",
    "\n",
    "LDA Approach is a unsupervised leraning algorithm to identify the topics that are hidden in a documents.\n",
    "Here we are trying to extarct the topic which related to MG hector car that is newly launched into the market.\n",
    "LDA Would able to extract the important topics from the customer reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"E:\\\\Text_Analytics\\\\MG_Hector.csv\",header=0,encoding = 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From whatever little information is available ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>However, this is a Chinese brand and they will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I doubt the future of MG in India with their r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>However, from what I've read so far, the Baoju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MG Hector petrol engine details revealed, seem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review\n",
       "0  From whatever little information is available ...\n",
       "1  However, this is a Chinese brand and they will...\n",
       "2  I doubt the future of MG in India with their r...\n",
       "3  However, from what I've read so far, the Baoju...\n",
       "4  MG Hector petrol engine details revealed, seem..."
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the count vectorizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = cv.fit_transform(df['Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<40x198 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 567 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are converted the reviews into matrix of columns using the count vectorizer.\n",
    "Let's import the LDA to perform topic identifying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to decide how many topics that we need to identify from LDA analyisis and we need to specify in n_components\n",
    "#Here I have tawken 5 topic\n",
    "LDA = LatentDirichletAllocation(n_components=3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='batch', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
       "             n_components=3, n_jobs=None, n_topics=None, perp_tol=0.1,\n",
       "             random_state=42, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA.fit(dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the words from the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "especially\n",
      "product\n",
      "comfortable\n",
      "showroom\n",
      "soon\n",
      "vehicles\n",
      "guess\n",
      "car\n",
      "details\n",
      "petrol\n"
     ]
    }
   ],
   "source": [
    "#getting the random words\n",
    "import random\n",
    "for i in range(10):\n",
    "    random_word_id = random.randint(0,190)\n",
    "    print(cv.get_feature_names()[random_word_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying the top words in a Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(LDA.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we decided earlier we are idebtifying 5 topics from the LDA Analyzis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3337817 ,  0.33357623,  1.34002325,  0.33363096,  0.33372938,\n",
       "         0.33357326,  2.33169144,  0.33354517,  0.3348114 ,  0.33374237,\n",
       "         0.33354481,  0.33360048,  7.33283598,  2.20885037,  0.33347785,\n",
       "         0.33382672,  0.55276529,  3.31404104,  0.33430821,  0.47980683,\n",
       "         1.3682048 ,  0.33379657,  0.33399717,  0.33364991,  0.78879325,\n",
       "         0.8350769 ,  1.32575089,  0.33345906,  1.34627516,  5.25459734,\n",
       "         0.34301075,  0.33353345,  0.3334314 ,  0.33344732,  0.3335305 ,\n",
       "         3.3635059 ,  0.36385051,  0.33348338,  0.33370876,  3.33224831,\n",
       "         0.33344604,  0.33429715,  0.33341261,  0.33346017,  0.33354444,\n",
       "         1.33557726,  1.33848773,  0.33354517,  3.33217886,  0.33345906,\n",
       "         1.32956219,  2.34608462,  0.33368743,  1.335615  ,  0.33363478,\n",
       "         2.24474108,  0.3334314 ,  0.33373309,  4.32392023,  0.33346642,\n",
       "         0.34752433,  0.33358204,  2.33297453,  0.3343559 ,  0.3343559 ,\n",
       "         2.32404912,  0.3337232 ,  0.33356461,  0.47095016,  0.50122545,\n",
       "         1.65727053,  0.3334314 ,  0.33389499,  0.33345906,  0.33362024,\n",
       "         0.39239727,  2.30517078,  0.35173759,  0.33345107,  0.35580807,\n",
       "         2.3331668 ,  0.33360536,  0.36374076,  0.33364549,  0.35173735,\n",
       "         0.33363515,  0.33364549,  0.33382672,  0.33353345,  0.33396281,\n",
       "         0.36374076,  0.33360987,  2.28829537,  0.3339023 ,  0.36398049,\n",
       "         0.33362027,  0.33351152,  1.39872886,  1.11543075,  1.33139468,\n",
       "         0.33435253,  1.33961305,  0.33366881,  3.02827726,  0.3337042 ,\n",
       "         0.33441803,  1.33346586,  0.33385494,  1.33693232, 12.3294377 ,\n",
       "         1.32465497,  0.33353144,  0.34088512,  0.33379938,  0.33348349,\n",
       "         2.32404928,  0.33345906,  0.38073218,  0.33347783,  2.29409032,\n",
       "         2.18643924,  0.33397985,  0.33347781,  0.33345906,  1.33411872,\n",
       "         1.34318378,  2.33180193,  0.36385051,  1.33571686,  0.33398953,\n",
       "         0.33351135,  0.33354517,  0.33346296,  0.33372033,  0.33342422,\n",
       "         1.33708972,  1.33228532,  1.32938467,  0.33402681,  4.28252606,\n",
       "         0.51238237,  0.33354517,  0.33358897,  0.33363008,  0.34287551,\n",
       "         0.3336608 ,  0.33375558,  1.33733919,  0.33858122,  0.3340302 ,\n",
       "         0.33354517,  0.33368491,  0.33412781,  0.33343054,  0.33373602,\n",
       "         0.3340047 ,  0.33372938,  0.33348003,  0.33390343,  0.33437427,\n",
       "         2.24702209,  0.33360651,  0.33368292,  1.33038151,  0.33358204,\n",
       "         0.33351135, 12.32942964,  2.32189457,  0.3334903 ,  0.33350157,\n",
       "         0.3335377 ,  1.33505144,  0.36892728,  0.33350786,  3.36792131,\n",
       "         0.33357469,  0.33345906,  0.3338739 ,  5.32837184,  0.33379938,\n",
       "         0.33381313,  0.33339585,  0.35138184,  0.33383333,  0.33344348,\n",
       "         0.3343915 ,  0.33347217,  0.33361108,  0.33347666,  2.09909804,\n",
       "         0.36523114,  2.31636489,  0.33345615,  0.33370402,  0.36453903,\n",
       "         0.33376831,  0.33372938,  2.27964574],\n",
       "       [ 2.53925286,  2.33297699,  1.3263723 ,  2.33289354,  1.338626  ,\n",
       "         0.33353052,  0.33346576,  0.33349676,  0.33394713,  1.3369856 ,\n",
       "         4.32580067,  0.89890319,  0.33340342,  0.33823366,  0.39272348,\n",
       "         1.34085531,  3.20393582,  0.33362663,  2.19633919,  0.40321185,\n",
       "         1.00122882,  0.33366033,  0.34041974,  5.83637153,  0.33416589,\n",
       "         0.33375477,  0.41089259,  2.31635174,  0.33434252,  2.33877342,\n",
       "         2.32333091,  0.39460293,  2.31500776,  1.33356147,  0.35427107,\n",
       "         0.33392675,  0.33354957,  0.33348775,  7.70311152,  0.33343253,\n",
       "         3.30772847,  1.34675537,  3.32212943,  5.33939425,  0.3393057 ,\n",
       "         0.33394521,  0.6432466 ,  0.33349676,  0.3334689 ,  2.31635172,\n",
       "         7.17484571,  0.58361762,  0.44823064,  3.32084537,  0.333593  ,\n",
       "         1.69915249,  2.31500782,  1.65877796,  1.32893086,  0.33344468,\n",
       "         1.7036394 ,  0.33350446,  0.33353292,  1.33599996,  1.33599996,\n",
       "         0.61376416,  2.40368725,  0.34249392,  0.33377692,  8.20046299,\n",
       "         0.37226063,  2.31500781,  3.35478146,  2.31635173,  0.39185236,\n",
       "         0.43996829,  1.33478339,  0.36727097,  1.3342087 ,  2.57991001,\n",
       "         0.3334289 ,  3.29656249,  0.33351163,  2.33289257,  0.36435919,\n",
       "         0.33358852,  2.33289257,  0.33370351,  0.39460293,  0.33379139,\n",
       "         0.33351163,  0.33354079,  3.34093028,  0.33367187,  0.33361669,\n",
       "         0.39199805,  7.33306968,  0.33462346,  0.36092427,  0.33349898,\n",
       "         0.36998897,  1.33689357,  0.39490385,  0.43833827,  3.15411015,\n",
       "         1.34584138,  1.33315076,  2.34958685,  1.33569167,  0.33343492,\n",
       "         0.33396468,  0.33348602,  0.34450553,  0.34263889,  1.33383979,\n",
       "         0.61377108,  2.31635173,  0.34238304,  0.39232597,  0.33363627,\n",
       "         0.47953119,  1.33930184,  0.39209079,  2.31635175,  1.33248118,\n",
       "         0.3337728 ,  0.33340055,  0.33354957,  1.27711435,  0.3338469 ,\n",
       "         0.33349709,  0.33349676,  3.12529656,  9.42411546,  0.33341632,\n",
       "         0.48711586,  1.33428265,  1.81471098,  0.33362732,  0.33362614,\n",
       "         0.33393683,  0.33349676,  0.33354123,  2.3329159 ,  2.32350933,\n",
       "         0.39239388,  1.49955953,  0.33370179,  1.29910953,  0.33381976,\n",
       "         0.33349676,  1.78963448,  0.34834384,  3.3231442 ,  1.34004258,\n",
       "         2.34770685,  1.338626  ,  3.32306287,  1.33519156,  1.83760355,\n",
       "         2.52627639,  2.0107839 ,  1.99699011,  2.12079503,  0.33350446,\n",
       "         0.33349709,  0.33343908,  0.33348953,  1.99122705,  4.3155513 ,\n",
       "         8.9073238 ,  0.50971063,  0.33355007,  2.31487393,  0.33383505,\n",
       "         0.33355113,  2.31635172,  0.33354491,  0.33354569,  0.34263889,\n",
       "         0.33350755,  2.33323902,  0.33352055,  0.3336657 ,  3.33669511,\n",
       "         0.34877515,  2.98839921,  1.33543041,  4.32513366,  0.33370289,\n",
       "         0.39347552,  1.31217643,  2.33314771,  1.65927325,  0.33379489,\n",
       "         1.33967379,  1.338626  ,  0.33390269],\n",
       "       [ 3.12696544,  0.33344677,  0.33360445,  0.33347549,  1.32764462,\n",
       "         3.33289622,  0.3348428 ,  2.33295807,  2.33124147,  2.32927203,\n",
       "         0.34065452,  1.76749633,  0.3337606 ,  5.45291597,  2.27379867,\n",
       "         1.32531797,  9.24329889,  2.35233233,  0.4693526 ,  2.11698132,\n",
       "         0.63056638,  5.3325431 ,  7.32558309,  0.82997856,  1.87704086,\n",
       "         1.83116833,  3.26335652,  0.3501892 ,  1.31938232,  1.40662924,\n",
       "         0.33365834,  2.27186362,  0.35156084,  2.33299121,  4.31219843,\n",
       "         2.30256735,  2.30259992,  3.33302887,  3.96317972,  0.33431916,\n",
       "         0.35882549,  1.31894748,  0.34445796,  2.32714558,  3.32714987,\n",
       "         1.33047754,  1.01826567,  2.33295807,  0.33435224,  0.35018922,\n",
       "         1.4955921 ,  1.07029776,  3.21808193,  0.34353963,  2.33277222,\n",
       "         4.05610643,  0.35156078,  1.00748895,  0.34714891,  4.3330889 ,\n",
       "         3.94883627,  3.33291351,  0.33349255,  1.32964414,  1.32964414,\n",
       "         1.06218672,  1.26258955,  2.32394147,  2.19527292,  1.29831156,\n",
       "         2.97046884,  0.35156079,  1.31132355,  0.35018921,  2.2745274 ,\n",
       "         3.16763444,  1.36004583,  3.28099144,  1.33234023, 15.06428193,\n",
       "         0.33340431,  0.36983215,  2.30274762,  0.33346194,  3.28390345,\n",
       "         2.33277632,  0.33346194,  2.33246977,  2.27186362,  3.3322458 ,\n",
       "         2.30274762,  4.33284934,  0.37077435,  4.33242583,  2.30240281,\n",
       "         2.27438168,  0.3334188 ,  1.26664767,  3.52364498,  2.33510635,\n",
       "         2.2956585 ,  4.32349338,  2.27142734,  1.53338447,  1.51218564,\n",
       "         1.31974058,  0.33338338,  1.31655822,  1.327376  ,  0.33712739,\n",
       "         3.34138035,  3.33298254,  7.31460935,  2.32356173,  1.33267672,\n",
       "         1.06217964,  0.35018921, 28.27688478,  2.2741962 ,  0.3722734 ,\n",
       "         0.33402957,  1.32671831,  2.2744314 ,  0.35018919,  0.3334001 ,\n",
       "         1.32304343,  0.33479753,  2.30259992,  0.38716878,  2.33216356,\n",
       "         3.33299155,  2.33295807,  1.54124048,  8.24216421,  4.33315946,\n",
       "         1.17579442,  0.33343203,  2.85590435,  3.33234587,  0.38384781,\n",
       "         3.1536808 ,  2.33295807,  2.3328698 ,  0.33345402,  0.33361516,\n",
       "         2.27394531,  2.1666849 ,  1.32895902,  1.36230925,  2.33215004,\n",
       "         2.33295807,  2.87668062,  2.31752834,  0.34342526,  1.32622139,\n",
       "         1.31828845,  1.32764462,  0.3434571 ,  1.33090501,  2.82802219,\n",
       "         3.22670152,  1.65560959,  1.66932697,  4.54882346,  3.33291351,\n",
       "         3.33299155,  0.33713128,  0.34461591,  1.67528264,  0.35094712,\n",
       "         2.7591385 ,  1.15523793,  4.29752265,  0.35161821,  1.29824364,\n",
       "         2.33287418,  0.35018922,  2.33258119,  0.33808247,  2.32356173,\n",
       "         2.33267932,  0.33336513,  3.31509761,  2.33250097,  2.32986141,\n",
       "         2.31683335,  2.67812862,  1.33095851,  0.34138968,  1.56719907,\n",
       "         2.24129334,  0.37145868,  0.33339614,  1.00702273,  2.30166607,\n",
       "         1.3265579 ,  1.32764462,  0.38645156]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we are extracting the probability of words in a topic. here we have 5 topic and each word has probability for each topic.\n",
    "Now we need to find out the highest probability of words in a topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(LDA.components_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_topic = LDA.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([181,  42, 134, 153,  56,  71,  32, 184,  40,  33,  78, 192, 123,\n",
       "        27, 116,  73,  49, 176,  43, 132,  59, 186, 188, 122, 118,  14,\n",
       "       157,  37, 114, 168, 169, 173, 165, 130,  96,  34, 111,  88,  31,\n",
       "       170,  44,  10,  47, 150, 131, 141,   7,  67,   5, 175,   1, 164,\n",
       "        61, 142,  11,  81, 161,  91, 187,  74,  95, 143,   3,  54,  85,\n",
       "        86,  83,  23, 145, 102, 162, 151,  52, 193, 104,  38, 133,  66,\n",
       "       156,   4, 196,  57, 154,   9, 146, 195,   0,  21, 179, 113, 180,\n",
       "        15,  87, 183, 107, 177,  72,  93, 158,  89, 121, 129,  22, 155,\n",
       "       138, 149, 152,  41,  18, 100,  64,  63, 159, 185, 105,   8, 148,\n",
       "       112, 144,  30,  60, 182,  84,  77,  79,  82,  90,  36, 127,  94,\n",
       "       194, 190, 172, 117,  75,  68,  19,  69, 140,  16,  24,  25,  98,\n",
       "       110,  26, 137,  50, 163,  99, 136, 106, 124, 171,  45,  53, 128,\n",
       "       108, 135, 147,  46, 101,   2, 125,  28,  20,  97,  70, 189, 120,\n",
       "        13,  55, 160, 197,  92, 119,  76, 191, 167,  65, 115,   6, 126,\n",
       "        62,  80,  51, 103,  17,  48,  39,  35, 174, 139,  58,  29, 178,\n",
       "        12, 166, 109], dtype=int64)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#argsort() return the indexes in sorted order from low probability to higher probabilty\n",
    "first_topic.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3341187231102016"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word that least able to expalin the topic is index'124'\n",
    "first_topic[124]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.282526057195967"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Word which has high probability ans can explain this topic mostly is index position '139'\n",
    "first_topic[139]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 words for this topic:\n",
    "top_word_indices = first_topic.argsort()[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deciding\n",
      "creta\n",
      "torque\n",
      "pricing\n",
      "factor\n",
      "compass\n",
      "tucson\n",
      "bracket\n",
      "support\n",
      "lumbar\n"
     ]
    }
   ],
   "source": [
    "#Now we have got index locatio of top ten words. Now we can pull corresponding words to get the topic understanding\n",
    "for index in top_word_indices:\n",
    "    print(cv.get_feature_names()[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify the top 15 words for each topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 words of topic #0\n",
      "['helps', 'drives', 'long', 'cars', 'don', 'deciding', 'creta', 'torque', 'pricing', 'factor', 'compass', 'tucson', 'bracket', 'support', 'lumbar']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The top 10 words of topic #1\n",
      "['said', 'vehicle', 'jeep', 'guess', 'td', 'wait', 'better', 'diesel', 'city', 'drive', 'kmpl', 'dct', 'good', 'test', 'petrol']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The top 10 words of topic #2\n",
      "['country', 'like', 'just', 'industry', 'feature', 'point', 'speed', 'china', 'brand', 'market', 'chinese', 'petrol', 'car', 'hector', 'mg']\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,topic in enumerate(LDA.components_):\n",
    "    print(f'The top 10 words of topic #{i}')\n",
    "    print([cv.get_feature_names()[index] for index in topic.argsort()[-15:]])\n",
    "    print('\\n')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Topic : \n",
    "\n",
    "First topic tells about factors that most decides in MG hector\n",
    "\n",
    "It tells about the Lumbar support which is laking in MG hector\n",
    "\n",
    "It also tells about the pricing of the car\n",
    "\n",
    "### Second Topic : Performance of the MG Hector\n",
    "\n",
    "Second topic more talks about the performance of the MG hector\n",
    "\n",
    "The TOPIC is about the milege, perfomance of petrol and diesel variants , city drive etc\n",
    "\n",
    "\n",
    "### Third Topic : MG Hector as a China Car\n",
    "\n",
    "This topic mainly identifyies the talks that related that Hector as a China Car.\n",
    "\n",
    "Some of the customers are indicating MG hector as a Chinese product and this will give negartive impact in indian markets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining with Original Data and identifyies Topics of Each Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 198)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<40x198 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 567 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformming entire matrix of data terms and getting their probability of each topics\n",
    "topic_results = LDA.transform(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 3)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01973863, 0.02079774, 0.95946363])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting the probability scores of first review.\n",
    "topic_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the highest probabilty and the first review identified as topic 3\n",
    "topic_results[0].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From whatever little information is available ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>However, this is a Chinese brand and they will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I doubt the future of MG in India with their r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>However, from what I've read so far, the Baoju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MG Hector petrol engine details revealed, seem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review\n",
       "0  From whatever little information is available ...\n",
       "1  However, this is a Chinese brand and they will...\n",
       "2  I doubt the future of MG in India with their r...\n",
       "3  However, from what I've read so far, the Baoju...\n",
       "4  MG Hector petrol engine details revealed, seem..."
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 0, 0, 0, 2, 1, 2, 2, 0, 1, 2, 2, 2, 2, 0, 0, 0, 0,\n",
       "       2, 2, 2, 0, 2, 2, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_results.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Topic'] = topic_results.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From whatever little information is available ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>However, this is a Chinese brand and they will...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I doubt the future of MG in India with their r...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>However, from what I've read so far, the Baoju...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MG Hector petrol engine details revealed, seem...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Look at the torque figures. That would more th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This one is a definite Creta rival. 2019 seems...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14-118 hp and 150 Nm of torque but with a 4-sp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The MG 3 looks uncannily similar to the Santro...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Quality and fit and finish are superb and are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Topic\n",
       "0  From whatever little information is available ...      2\n",
       "1  However, this is a Chinese brand and they will...      2\n",
       "2  I doubt the future of MG in India with their r...      2\n",
       "3  However, from what I've read so far, the Baoju...      2\n",
       "4  MG Hector petrol engine details revealed, seem...      2\n",
       "5  Look at the torque figures. That would more th...      0\n",
       "6  This one is a definite Creta rival. 2019 seems...      0\n",
       "7  14-118 hp and 150 Nm of torque but with a 4-sp...      0\n",
       "8  The MG 3 looks uncannily similar to the Santro...      2\n",
       "9  Quality and fit and finish are superb and are ...      1"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
